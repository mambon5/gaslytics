
- [Plan](#plan)
- [Vista precisa](#vista-precisa)
  - [Plan](#plan-1)
  - [Permisos pel servidor](#permisos-pel-servidor)
  - [Servei per mostrar les dades descaregades](#servei-per-mostrar-les-dades-descaregades)
  - [Virtual host en apache per fer accessible la app desde fora](#virtual-host-en-apache-per-fer-accessible-la-app-desde-fora)
  - [si el servei kpler\_fetch.service dona errors:](#si-el-servei-kpler_fetchservice-dona-errors)
  - [Error al executar la streamlit app al meu servidor de mireia 77](#error-al-executar-la-streamlit-app-al-meu-servidor-de-mireia-77)
  - [Sense pandas i numpy el servidor antic funciona](#sense-pandas-i-numpy-el-servidor-antic-funciona)
  - [visualitzaciÃ³ de les dades de kpler descarregades](#visualitzaciÃ³-de-les-dades-de-kpler-descarregades)
- [Dades de kpler guardades:](#dades-de-kpler-guardades)

# Plan

Crear un servei de linyx `systemd`, Ã©s a dir un fitxer `.service` i un timer `.timer` que cridi el servei cada dia a els 2 am. I el servei ha de fer dues coses:

1. Descarregar de la api de kpler totes les dades cada dia
2. Mantenir un csv histÃ²ric amb dades deduplicades.

# Vista precisa

## Plan

ğŸ”¹ 1. Automatitzar amb systemd

El que proposes (.service + .timer) Ã©s perfecte per un servidor Linux:

myjob.service â†’ defineix com executar el teu contracts.py (per exemple amb un virtualenv).

myjob.timer â†’ sâ€™encarrega de llanÃ§ar el .service a les 2:00 de la matinada cada dia.

Exemple senzill:

/etc/systemd/system/contracts.service

```
[Unit]
Description=DescÃ rrega diÃ ria de dades Kpler

[Service]
Type=simple
WorkingDirectory=/var/www/gaslytics/kpler/src_automatic_09_2025
ExecStart=/var/www/gaslytics/kpler/src_automatic_09_2025/venv/bin/python3 /var/www/gaslytics/kpler/src_automatic_09_2025/kpler_
fetch_all_auto.py
User=romanov
Group=romanov
Restart=on-failure

[Install]
WantedBy=multi-user.target

```


/etc/systemd/system/contracts.timer
```
[Unit]
Description=Timer per executar Kpler Fetch cada dia a les 2 AM

[Timer]
OnCalendar=*-*-* 02:00:00
Persistent=true

[Install]
WantedBy=timers.target

```
DesprÃ©s:
```
sudo systemctl daemon-reload
sudo systemctl enable kpler_fetch.timer
sudo systemctl start kpler_fetch.timer
sudo systemctl status kpler_fetch.timer


```
watch logs:

```
journalctl -u kpler_fetch.service -f

```

mb aixÃ², cada dia a les 2:00am tens el CSV nou.
I amb systemctl list-timers veus quan sâ€™executarÃ  el segÃ¼ent.

ğŸ”¹ 2. Evitar duplicats i nomÃ©s fer append

Ara mateix el teu script torna a guardar totes les dades en un fitxer nou cada dia.
Tens dues opcions:

OpciÃ³ A â†’ Fitxer diferent per cada dia (com tens ara)

Avantatge: tens un histÃ²ric complet diari.

Desavantatge: hi pot haver moltes dades duplicades si lâ€™API retorna sempre tot.

OpciÃ³ B â†’ Fitxer Ãºnic que es va ampliant

Per fer aixÃ², pots carregar el CSV existent i fer append nomÃ©s de les files noves. Exemple:
```
import os
import pandas as pd

today_str = datetime.today().strftime("%Y-%m-%d")
output_path = "data/kpler_contracts.csv"

# nou dataframe de l'API
df_new = pd.read_csv(StringIO(response.text), sep=";")

if os.path.exists(output_path):
    df_old = pd.read_csv(output_path)
    # combinar i eliminar duplicats
    df = pd.concat([df_old, df_new]).drop_duplicates()
else:
    df = df_new

df.to_csv(output_path, index=False)
print(f"âœ… Data updated to {output_path}")

```

El fitxer de python que descarrega totes les dades es diu `kpler_fetch_all_auto.py`.

## Permisos pel servidor

Recordeu posar totes les carpetes de `/var/www/gaslytics/kpler/` i del virtual environment, amb permisos poc restrictius perquÃ¨ el servei Apache les pugui obrir i executar!Ã§


## Servei per mostrar les dades descaregades

Farem una app amb Streamlit que permeti mostrar, navegar i descarregar els csv guardats.

Servei hauria de ser quelcom aixÃ­: `kpler_show_css.service`

amb el codi:

```
[Unit]
Description=Streamlit App - Gaslytics
After=network.target

[Service]
User=romanov
WorkingDirectory=/var/www/gaslytics/kpler/src_automatic_09_2025
ExecStart=/var/www/gaslytics/kpler/src_automatic_09_2025/venv/bin/python3 -m streamlit run app.py \
  --server.headless true \
  --server.port 8501 \
  --server.address 0.0.0.0 \
  --server.enableCORS false \
  --server.enableXsrfProtection false
Restart=always

[Install]
WantedBy=multi-user.target
```
lu de `headless true`, es important per dir-li a streamlit que no demani el email per la terminal al executar-se la aplicaciÃ³ ja que aixÃ² donaria error.

executar el servei:

```
sudo systemctl daemon-reload
sudo systemctl restart kpler_show_css.service
sudo systemctl status kpler_show_css.service
```
Podem dir-li al servidor que executi de forma automÃ tica aquest servei al fer boot, amb la instrucciÃ³:
```
sudo systemctl enable kpler_show_css.service
```


url local per veure la app: `http://localhost:8501`

## Virtual host en apache per fer accessible la app desde fora 

Farem el segÃ¼ent virtual host per poder conectar els visitants al router que vinguin per un domini en concret, al port local on estÃ  la app al servidor.
El fitxer estÃ  en aquesta carpeta i es diu `gaslytics_css.conf` i tÃ© el segÃ¼ent contigut:

```
<VirtualHost *:80>
    ServerName gaslytics.nescolam.com

    ProxyPreserveHost On
    ProxyRequests Off
    RewriteEngine On

    # WebSockets
    RewriteCond %{HTTP:Upgrade} websocket [NC]
    RewriteRule ^/(.*) ws://localhost:8501/$1 [P,L]

    # HTTP normal
    RewriteCond %{HTTP:Upgrade} !websocket [NC]
    RewriteRule ^/(.*) http://localhost:8501/$1 [P,L]

    ProxyPassReverse / http://localhost:8501/
    <Proxy "http://localhost:8501/">
        Require all granted
    </Proxy>

    ErrorLog ${APACHE_LOG_DIR}/gaslytics_error.log
    CustomLog ${APACHE_LOG_DIR}/gaslytics_access.log combined
</VirtualHost>

```


## si el servei kpler_fetch.service dona errors:

recrear el virtual env de nou:

```
cd /var/www/gaslytics/kpler/src_automatic_09_2025
sudo rm -rf venv
sudo python3 -m venv venv
source venv/bin/activate
pip3 install --upgrade pip
pip3 install pandas requests
```

## Error al executar la streamlit app al meu servidor de mireia 77

Error que `illegal instruction` que trobo tot el rato indica que el CPU del meu servidor Ã©s massa antic per fer correr les dependÃ¨ncies de Streamlit. Ã‰s a dir, no puc usar Streamlit. Farem una flask app millor.

AixÃ² passa perquÃ¨ usem la llibreria pandas que depen de numpy i tÃ© instruccions precompliades amb C que usen el processador modern AVX que el meu pc potser no suporta.

## Sense pandas i numpy el servidor antic funciona  

RecopilaciÃ³ de com ha de funcionar els serveis:


## visualitzaciÃ³ de les dades de kpler descarregades
S'han de poder veure les dades de kpler aqui `http://gaslytics.nescolam.com/`


# Dades de kpler guardades:

Estem guardant aquesta informaciÃ³:

| Taula                          | DescripciÃ³                                                                                              | Relacions clau                                                                                                                     |
| ------------------------------ | ------------------------------------------------------------------------------------------------------- | ---------------------------------------------------------------------------------------------------------------------------------- |
| **contracts**                  | Contractes de subministrament de LNG entre *sellers* i *buyers* (capacitat, durada, origen/destinaciÃ³). | â†”ï¸ `installations` (zones dâ€™origen i destinaciÃ³) <br>â†”ï¸ `flows` (moviments reals de gas)                                           |
| **diversions**                 | Vaixells que canvien destÃ­ o rumb en un viatge LNG.                                                     | â†”ï¸ `installations` (ports o plantes dâ€™origen i destÃ­) <br>â†”ï¸ `trades` (moviment comercial original)                                |
| **flows**                      | Fluxos diaris dâ€™LNG per paÃ­s (importacions/exportacions).                                               | â†”ï¸ `contracts` (per identificar acords que expliquen els fluxos) <br>â†”ï¸ `storages` (part dels fluxos pot acabar en emmagatzematge) |
| **installations**              | Llista de plantes i terminals LNG (import/export, paÃ­s, operador, capacitat).                           | â†”ï¸ `contracts`, `diversions`, `outages`, `storages inv installations`                                                              |
| **outages**                    | Parades planificades o no planificades de plantes LNG.                                                  | ğŸ”— `installation name` â†’ `installations.installation`                                                                              |
| **storages inv countries**     | Volums totals dâ€™emmagatzematge per paÃ­s.                                                                | â†”ï¸ `flows` (entrades/sortides de gas)                                                                                              |
| **storages inv installations** | Mateixa informaciÃ³, perÃ² per instalÂ·laciÃ³ concreta.                                                     | ğŸ”— `installation` â†’ `installations.installation`                                                                                   |
| **trades**                     | Moviments comercials de LNG entre paÃ¯sos (origen/destinaciÃ³).                                           | â†”ï¸ `contracts` (si provenen dâ€™un acord) <br>â†”ï¸ `diversions` (si un vaixell canvia de destÃ­)                                        |


ğŸ‘‰ En resum:
installations Ã©s el nucli fÃ­sic (infraestructura),
contracts i trades sÃ³n la part comercial,
flows i storages la part operativa,
diversions i outages els esdeveniments que afecten el flux normal.

per fer aixÃ² farem dos arxius en python per guardar els csv en una base de dades mysql relacional. L'estructura del arbre de fitxers seria la segÃ¼ent:
```
gaslytics/
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ kpler_contracts.csv
â”‚   â”œâ”€â”€ kpler_installations.csv
â”‚   â”œâ”€â”€ kpler_flows.csv
â”‚   â”œâ”€â”€ kpler_outages.csv
â”‚   â”œâ”€â”€ kpler_trades.csv
â”‚   â”œâ”€â”€ kpler_diversions.csv
â”‚   â””â”€â”€ kpler_storages_inv_installations.csv
â”œâ”€â”€database/
â”‚   â”œâ”€â”€ models.py          # models SQLAlchemy
â”‚   â””â”€â”€ load_data.py       # script per carregar CSVs
```